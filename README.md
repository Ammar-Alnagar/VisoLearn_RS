# VisoLearn

![VisoLearn Logo](static/logo.png)  
**VisoLearn** is an AI-powered educational tool designed to help autistic children improve communication and observational skills through interactive visual learning. The system generates custom images based on a child's learning needs and evaluates their descriptions to provide real-time feedback and guidance.

---

## ğŸš€ Key Features
- **AI-Powered Image Generation** â€“ Uses **Stable Diffusion** to create tailored images based on user-defined criteria.
- **Vision-Language Evaluation** â€“ Implements **Qwen-VL Max** to analyze user descriptions and measure comprehension.
- **Personalized Learning Adaptation** â€“ Dynamically adjusts difficulty based on individual progress.
- **Interactive Feedback Loop** â€“ Provides hints, suggestions, and multiple attempts for description refinement.
- **Session Tracking & Data Analysis** â€“ Logs learning progress, allowing for comprehensive assessment over time.

---

## ğŸ“¦ Installation Guide
### Prerequisites
- **Rust** (latest stable release)
- **Cargo** package manager
- **Python** (for optional ML integrations)
- **NVIDIA GPU** (recommended for optimal performance with Stable Diffusion)

### Setup Instructions
```sh
# Clone the repository
git clone https://github.com/Ammar-Alnagar/VisoLearn.git
cd VisoLearn

# Build the project
cargo build --release

# Run the application
cargo run --release
```

---

## ğŸ“‚ Project Structure
```plaintext
VisoLearn/
â”œâ”€â”€ Cargo.toml             # Main package manifest (dependencies, metadata, and configurations)
â”œâ”€â”€ Cargo.lock             # Lock file to ensure reproducible builds
â”œâ”€â”€ src/                   # Main source directory
â”‚   â”œâ”€â”€ main.rs            # Application entry point, initializes core services
â”‚   â”œâ”€â”€ config.rs          # Configuration settings (environment variables, paths, model parameters)
â”‚   â”œâ”€â”€ models/            # AI model integration
â”‚   â”‚   â”œâ”€â”€ mod.rs         # Module declarations for models
â”‚   â”‚   â”œâ”€â”€ evaluation.rs  # Image description evaluation logic using Qwen-VL Max
â”‚   â”‚   â”œâ”€â”€ image_generation.rs # Image generation pipeline with Stable Diffusion
â”‚   â”‚   â”œâ”€â”€ prompt_generation.rs # Adaptive prompt creation for educational exercises
â”‚   â”œâ”€â”€ ui/                # User interface components
â”‚   â”‚   â”œâ”€â”€ mod.rs         # UI module entry point
â”‚   â”‚   â””â”€â”€ interface.rs   # Interface logic for handling user interactions
â”‚   â””â”€â”€ utils/             # Utility functions for system operations
â”‚       â”œâ”€â”€ mod.rs         # Module declarations
â”‚       â”œâ”€â”€ file_operations.rs # File I/O operations for saving/loading images and logs
â”‚       â”œâ”€â”€ state_management.rs # Handles session persistence and user progress tracking
â”‚       â””â”€â”€ visualization.rs # UI helpers for rendering educational content
â”œâ”€â”€ static/                # Static assets such as icons, templates, and pre-trained models
â”œâ”€â”€ tests/                 # Integration tests for AI models and system components
â”œâ”€â”€ benches/               # Performance benchmarking for AI components
â”œâ”€â”€ examples/              # Example datasets and usage scenarios
â”œâ”€â”€ .env                   # Environment variables for API keys, model paths, etc.
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ LICENSE                # MIT License file
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸ› ï¸ Technical Architecture
VisoLearn is built on a modular architecture, ensuring scalability and efficiency. The core system components include:

### 1ï¸âƒ£ **Image Generation**
- Utilizes **Stable Diffusion Large Turbo** for real-time image synthesis.
- Adjusts visual complexity based on the child's cognitive level.
- Ensures images are clear, calm, and conducive to learning.

### 2ï¸âƒ£ **Prompt Generation**
- Creates structured educational prompts tailored to different learning levels.
- Uses **LLaMA 3.3 70B** for dynamic language-based adjustments.

### 3ï¸âƒ£ **Evaluation System**
- Implements **Qwen-VL Max** for detailed response analysis.
- Compares child's descriptions to an AI-generated "ground truth."
- Extracts key elements and provides targeted feedback.

### 4ï¸âƒ£ **Feedback Mechanism**
- Provides step-by-step hints if key elements are missing.
- Offers multiple attempts before generating a new image.
- Adjusts future tasks based on previous performance.

### 5ï¸âƒ£ **State Management & Tracking**
- Logs and tracks learning sessions.
- Enables educators to review a child's improvement over time.
- Uses **Rustâ€™s stateful concurrency** for efficient tracking.

### 6ï¸âƒ£ **User Interface (UI)**
- Designed for simplicity and accessibility.
- Allows caregivers to configure learning parameters easily.
- Supports **text-to-speech** for auditory guidance.

---

## ğŸ“Š Benchmarks & Performance
VisoLearn is optimized for **low-latency interaction**. Below are benchmark results for core AI operations:

| Component | Avg Time (ms) | Performance Optimization |
|-----------|--------------|--------------------------|
| **Image Generation** | 1200ms | Using optimized **Stable Diffusion** inference |
| **Evaluation** | 350ms | Qwen-VL Max runs on CUDA-optimized PyTorch |
| **Feedback Processing** | 200ms | Efficient prompt structuring for real-time suggestions |

---

## ğŸ¤ Contributing to VisoLearn
We welcome contributions from the community! Hereâ€™s how you can contribute:

1. **Fork the Repository** â€“ Clone the project and create a new branch.
   ```sh
   git checkout -b feature-name
   ```
2. **Make Your Changes** â€“ Implement new features or fix bugs.
3. **Commit Your Work** â€“ Write clear and concise commit messages.
   ```sh
   git commit -m "Added feature X"
   ```
4. **Push & Open a PR** â€“ Submit your changes for review.
   ```sh
   git push origin feature-name
   ```

---

## ğŸ“œ License
VisoLearn is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

## ğŸ’¡ Acknowledgments
Special thanks to the **open-source community** and contributors for making AI-driven education more accessible!

**Developed by [Ammar Alnagar](https://www.linkedin.com/in/ammar-alnagar-393413201/) ğŸš€**

